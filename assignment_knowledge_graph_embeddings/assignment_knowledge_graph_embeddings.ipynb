{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment — Knowledge Graph Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment we will see how to use the TorchKDE library for building knowledge graphs and its embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hashlib import sha1\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 . Dataset exploration (4 points)\n",
    "\n",
    "To begin with we are going to need a knowledge graph, so let us load a standard knowledge graph dataset called _Freebase-15k-237_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_knowledge_graph_embeddings/freebase-237-merged-and-remapped.csv'\n",
    "open('freebase-237-merged-and-remapped.csv', 'wb').write(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('freebase-237-merged-and-remapped.csv', \n",
    "                 names=['h', 'r', 't'])\n",
    "df = df[~df.h.str.startswith('/') & ~df.t.str.startswith('/')]\n",
    "df[::1001].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is h — head (also subject), r — relation (also predicat), t — tail (also object). The shape of the dataset is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the number of unique entities and unique relations.\n",
    "\n",
    "Write a funtion `n_ent_rel` that takes a dataset and returns a number of unique entities and unique relations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e835a990ce88589b1e4baa4e213e5aed",
     "grade": false,
     "grade_id": "cell-a1c37b647b2bd8d4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def n_ent_rel(df):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "457b1d76d92cd69061834073e19c024f",
     "grade": true,
     "grade_id": "cell-e297130eb1b840de",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_ent, n_rel = n_ent_rel(df)\n",
    "assert sha1((str(n_ent + n_ent)).encode('utf-8')).hexdigest() == '2a5452eba9870d4f95a77176bbab9b5a862bda60'\n",
    "n_ent, n_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to find some facts in this dataset. For example, what is Harrison Ford's nationality? (\"harrison ford\" in the dataset)\n",
    "\n",
    "Write a function `harrison_ford_nationality` that takes a dataset and returns the nationality.\n",
    "\n",
    "_Hint: use pandas.Series.str.contains method_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f23d23c2036f17a865ee09c5de46253",
     "grade": false,
     "grade_id": "cell-bf2eb40c10e9971d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def harrison_ford_nationality(df):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80901f5603832e6ac57d03b628fe1dcd",
     "grade": true,
     "grade_id": "cell-e20681a97039cdf6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert sha1(harrison_ford_nationality(df).encode('utf-8')).hexdigest() == '2da4d0b37c841952f402a493ade05c98f19f4a14'\n",
    "harrison_ford_nationality(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More tricky question: who are film directors of movies where Harrison Ford was?\n",
    "\n",
    "Write a function `made_films_with_harrison_ford` that returns a set of directors' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac4a71f632063e89560fc4127de263b1",
     "grade": false,
     "grade_id": "cell-7ea1e48135c759d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def made_films_with_harrison_ford(df):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb9ed2af8b0884d3ed72461c15a28211",
     "grade": true,
     "grade_id": "cell-f3dbc03094dcbb5b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "directors = made_films_with_harrison_ford(df)\n",
    "assert sha1(str(sorted(directors)).encode('utf-8')).hexdigest() == 'c317bd28b873d3ae1a0444d9351d9d0ff5f2f348'\n",
    "directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. ComplEx embedding model (3 points)\n",
    "\n",
    "We will use TorchKDE — a Python module for knowledge graph (KG) embedding relying solely on Pytorch. Let us install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchkge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchkge\n",
    "from torchkge.models import ComplExModel, TransEModel\n",
    "from torchkge.utils import Trainer, MarginLoss\n",
    "from torchkge.evaluation import LinkPredictionEvaluator, TripletClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ComplEx scoring function is based on the trilinear Hermitian dot product\n",
    "$$f=\\text{Re}\\left(\\langle w_\\text{r}, e_\\text{h}, \\overline{e}_\\text{t}  \\rangle\\right)$$\n",
    "where \n",
    "* $w_\\text{r}$, $e_\\text{h}$, ${e}_\\text{t}$ are embeddings for relation, head, tail\n",
    "* $\\text{Re}(x)$ is a real part of $x$\n",
    "* $\\overline x = \\text{Re}(x) - i\\text{Im}(x)$\n",
    "\n",
    "Let us look at the WikiDataSet that presents country-specific subgraphs of Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_knowledge_graph_embeddings/countries_edges.tsv'\n",
    "open('countries_edges.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_knowledge_graph_embeddings/countries_entities.tsv'\n",
    "open('countries_entities.tsv', 'wb').write(requests.get(url).content)\n",
    "url = 'https://raw.githubusercontent.com/vpozdnyakov/network_science_assignments/master/assignment_knowledge_graph_embeddings/countries_relations.tsv'\n",
    "open('countries_relations.tsv', 'wb').write(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.read_csv('countries_edges.tsv', sep='\t').values\n",
    "entity_labels = pd.read_csv('countries_entities.tsv', sep='\t', index_col=0).label.values\n",
    "relation_labels = pd.read_csv('countries_relations.tsv', sep='\t', index_col=0).label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_labeled = np.stack([entity_labels[edges[:, 0]], \n",
    "                          entity_labels[edges[:, 1]], \n",
    "                          relation_labels[edges[:, 2]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(edges_labeled[10::1002], columns=['h', 't', 'r'])[['h', 'r', 't']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model minimizes Margin loss\n",
    "\n",
    "$\\mathcal L = \\max\\{0, \\gamma - f(h,r,t) + f(h',r',t')\\}$ where\n",
    "* $\\gamma$ is the margin (defined at initialization),\n",
    "* $f(h,r,t)$ is the score of a true fact and\n",
    "* $f(h',r',t')$ is the score of the associated negative fact.\n",
    "\n",
    "Let us convert our dataset into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = torchkge.KnowledgeGraph(\n",
    "    pd.DataFrame(edges_labeled, columns=['from', 'to', 'rel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us split the dataset into train and test set. What differs from the standard method of randomly sampling N points to make up our test set, is that our data points are two entities linked by some relationship, and we need to take care to ensure that all entities are represented in train and test sets by at least one triple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_train, kg_test = kg.split_kg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go through the parameters to understand what’s going on:\n",
    "* `emb_dim` is the dimensionality of the embedding space\n",
    "* `margin` is the $\\gamma$ parameter of Margin loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "margin = 0.5\n",
    "n_epochs = 150\n",
    "batch_size = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransEModel(emb_dim, kg_train.n_ent, kg_train.n_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MarginLoss(margin)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, criterion, kg_train, n_epochs, batch_size,\n",
    "                  optimizer=optimizer, sampling_type='bern')\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = LinkPredictionEvaluator(model, kg_test)\n",
    "evaluator.evaluate(b_size=32, k_max=10)\n",
    "evaluator.print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Hit@k` indicates how many times in average a true triple was ranked in the top-k. Therefore, on average, we guessed the correct subject or object 25% of the time when considering the top-10 better ranked triples. The choice of which k makes more sense depends on the application.\n",
    "\n",
    "* `Mean Rank` is a mean rank of the true entity when replacing alternatively head and tail in any fact of the dataset.\n",
    "\n",
    "* `MRR` is an average of mean recovery rank for head and tail replacement.\n",
    "\n",
    "* Filtered metrics are given with replacing alternatively head and tail in any fact of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us find a nearest neighbors of Belgium using embedding space.\n",
    "\n",
    "Write a function `similar_countries` that takes a name of country, graph and model and returns a list with names of nearest countries. Use `model.get_embeddings()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2914a4ae39cc291785e97e21b00d67ae",
     "grade": false,
     "grade_id": "cell-fe878bfa8dc0c817",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def similar_countries(name, kg, model):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c2c850ac3f262bd5d8cfb579bbe0201",
     "grade": true,
     "grade_id": "cell-0b8b02590a965cc3",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "similar = similar_countries('Belgium', kg, model)\n",
    "assert 'Netherlands' in similar\n",
    "similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Predicting New Links (3 points)\n",
    "\n",
    "Let us ckeck these facts:\n",
    "1. Belgium shares border with France\n",
    "2. Belgium shares border with Switzerland\n",
    "3. Belgium shares border with Nigeria\n",
    "\n",
    "Write a function `score_facts` that takes a model, a graph and returns 3 values of scoring function for each fact. Use `model.scoring_function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "036139dc351b131d80e17e536030f25f",
     "grade": false,
     "grade_id": "cell-5feee5e866b961d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_facts(model, kg):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85fbf178f6e27559a4943af25433074e",
     "grade": true,
     "grade_id": "cell-a6b6e4e88ba6569f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scores = score_facts(model, kg)\n",
    "assert scores[0] > scores[1] > scores[2]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
